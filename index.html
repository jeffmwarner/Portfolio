<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Symptom Triage</title>
<link rel="stylesheet" type="text/css" href="/Portfolio/styles.css">
</head>
<!-- <h2>Try a Sample Mental Health Intake Prompt</h2>
<div>
  <textarea id="userInput" rows="4" placeholder="Tell me a bit about how you're feeling today..."></textarea>
  <br />
  <button id="sendRealBtn">Ask the assistant</button>
</div>
<pre id="realAssistantOutput" class="assistant-output"></pre> -->

<h2>Scripted Conversation Flow Demo</h2>
<p>
  This example shows a predetermined hypertension flow with assistant and user messages.
</p>

<div id="scripted-chat" class="chat-container">
  <div id="chat-log"></div>

  <!-- Dynamic input area (text or choices appear here when needed) -->
  <div id="chat-input-area" class="chat-input-area">
    <!-- Filled by JS depending on the current step -->
  </div>
</div>


<script>
  const API_URL = "https://conversation-backend-yxsq.onrender.com/api/chat"; // my backend URL at Render

  document.getElementById("sendRealBtn").addEventListener("click", async () => {
    const inputEl = document.getElementById("userInput");
    const outputEl = document.getElementById("realAssistantOutput");
    const text = inputEl.value.trim();

    if (!text) {
      outputEl.textContent = "Please type something so I can send it to the assistant.";
      return;
    }

    outputEl.textContent = "...";

    try {
      const res = await fetch(API_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message: text })
      });

      if (!res.ok) {
        outputEl.textContent = "The assistant ran into a problem. Please try again later.";
        return;
      }

      const data = await res.json();

      const formatReply = (text) => {
        return text.replace(/([.?!])\s+/g, '$1\n\n');
      }
      
      outputEl.textContent = data.reply;
    } catch (err) {
      console.error(err);
      
      outputEl.textContent = "Network error talking to the assistant.";
    }
  });
</script>
<script>
  

  // --- Predetermined conversation script with optional routing fields ---

const conversationScript = [
  {
    type: "bot",
    stepId: "intro1",
    next: "intro2",
    text: `Hi there Ñ IÕm here to help you get connected with care.`,
  },
  {
    type: "bot",
    stepId: "intro2",
    next: "askConcern",
    text: `To get started`,
  },
  {
    type: "choice",
    stepId: "focusChoice",
    branches: { "Stress": "stressPath", "Sleep": "sleepPath", "Depression": "depressionPath" },
    id: "focusArea",
    prompt: `Which area feels most important to talk about first?`,
    choices: ["Stress", "Sleep", "Depression", "Anxiety"],
  },
  {
    type: "bot",
    stepId: "stressPath",
    next: "stressLLM",
    text: `LetÕs talk through stress first.`,
  },
  {
    type: "llmBot",
    stepId: "stressLLM",
    next: "rejoin",
    source: "focusArea",
    endpoint: "https://conversation-backend-yxsq.onrender.com/api/chat",
  },
  {
    type: "bot",
    stepId: "sleepPath",
    next: "sleepLLM",
    text: `Sleep problems can impact everything. Let's unpack that.`,
  },
  {
    type: "llmBot",
    stepId: "sleepLLM",
    next: "rejoin",
    source: "focusArea",
    endpoint: "https://conversation-backend-yxsq.onrender.com/api/chat",
  },
  {
    type: "bot",
    stepId: "depressionPath",
    next: "depLLM",
    text: `Thanks for bringing up depression Ñ thatÕs important.`,
  },
  {
    type: "llmBot",
    stepId: "depLLM",
    next: "rejoin",
    source: "focusArea",
    endpoint: "https://conversation-backend-yxsq.onrender.com/api/chat",
  },
  {
    type: "bot",
    stepId: "anxietyPath",
    next: "anxietyLLM",
    text: `While anxiety can be helpful in the right situation, too much anxiety at the wrong time can be a lot to manage.`,
  },
  {
    type: "llmBot",
    stepId: "anxietyLLM",
    next: "rejoin",
    source: "focusArea",
  },
  {
    type: "bot",
    stepId: "rejoin",
    next: "nextStep",
    text: `Before we wrap up`,
  },
  {
    type: "choice",
    stepId: "nextStep",
    next: "final",
    id: "nextStepChoice",
    prompt: `Choose one`,
    choices: ["Get matched with a therapist", "Learn what therapy is like", "Try coping strategies"],
  },
  {
    type: "bot",
    stepId: "final",
    text: `Thanks! This is only a short demo, but this framework scales to a full intake experience.`,
  },
];

    
  const AAAconversationScript = [
    {
      type: "bot",
      stepId: "intro1",
      text: "Hello! I'm your digital assistant, here to help with your recent hypertension (high blood pressure) diagnosis.",
      next: "intro2",
    },
    {
      type: "bot",
      stepId: "intro2",
      text: "There's a lot of things to cover, and it can feel overwhelming...",
      next: "intro3",
    },
    {
      type: "bot",
      stepId: "intro3",
      text: "...but that's where we can help!",
      next: "focusChoice",
    },
    {
      type: "choice",
      stepId: "focusChoice",
      id: "focusArea",
      prompt:
        "If you had to choose one area to focus on first, which feels most important?",
      choices: [
        "Signs and symptoms",
        "Measuring blood pressure",
        "Medication concerns",
      ],
      // You can branch each choice to its own path later if you want.
      // For now, we'll just send whatever they pick to the LLM.
      next: "focusLLM",
    },
    {
      type: "llmBot",
      stepId: "focusLLM",
      source: "focusArea", // use the user's choice as input to the LLM
      // id: "focusExplanation", // optional: store LLM reply in state
      // endpoint: "/api/chat",   // optional override (defaults to API_URL)
    },
  ];

  // Optional experimental scripts you had before (kept for reference)
  const ZZZconversationScript = [
    {
      type: "bot",
      text: "Hi, I'm here to help you get connected with care.",
    },
    {
      type: "llmInput",
      id: "presentingConcern",
      prompt:
        "To start, what's the main thing you're hoping to get support with right now?",
    },
    {
      type: "choice",
      id: "focusArea",
      prompt:
        "If you had to choose one area to focus on first, which feels most important?",
      choices: ["Managing anxiety or stress", "Sleep problems", "Depression"],
    },
    {
      type: "choice",
      id: "button",
      prompt: "Got it! We'll keep that in mind as a starting point.",
      choices: ["Thanks"],
    },
  ];

  const YYYconversationScript = [
    {
      type: "bot",
      text: "Hi, I'm here to help you get connected with care.",
    },
    {
      type: "userInput",
      id: "presentingConcern",
      prompt:
        "To start, what's the main thing you're hoping to get support with right now?",
    },
    {
      type: "bot",
      text: "Thank you for sharing that. That sounds really important.",
    },
    {
      type: "choice",
      id: "focusArea",
      prompt:
        "If you had to choose one area to focus on first, which feels most important?",
      choices: ["Managing anxiety or stress", "Sleep problems", "Depression"],
    },
    {
      type: "userInput",
      id: "button",
      prompt:
        "Got it! We'll keep that in mind as a starting point. {{focusArea}} is an important topic.",
    },
  ];

  const XXXconversationScript = [
    {
      type: "bot",
      text: "Hi, I'm here to help you get connected with care. I'll ask a few quick questions to better understand what you need.",
    },
    {
      type: "userInput",
      id: "presentingConcern",
      prompt:
        "To start, what’s the main thing you’re hoping to get support with right now?",
    },
    {
      type: "bot",
      text: (state) => {
        return `Thank you for sharing that. It sounds like you're dealing with: “${state.presentingConcern}”. That’s a lot to carry.`;
      },
    },
    {
      type: "choice",
      id: "focusArea",
      prompt:
        "If you had to choose one area to focus on first, which feels most important?",
      choices: [
        "Managing anxiety or stress",
        "Mood / depression",
        "Sleep problems",
        "Relationships and boundaries",
        "I’m not sure yet",
      ],
    },
    {
      type: "bot",
      text: (state) => {
        return `Got it. We'll keep “${state.focusArea}” in mind as a starting point.`;
      },
    },
    {
      type: "userInput",
      id: "timeline",
      prompt: "How long have you been dealing with this, roughly?",
    },
    {
      type: "bot",
      text: (state) => {
        return `Thanks. Knowing that this has been going on for about ${state.timeline} helps give context.`;
      },
    },
    {
      type: "choice",
      id: "nextStep",
      prompt: "What feels like the next most helpful step?",
      choices: [
        "Explore matching with a therapist",
        "Learn more about what therapy is like",
        "See coping strategies I can try on my own first",
      ],
    },
    {
      type: "bot",
      text: (state) => {
        if (state.nextStep.includes("matching")) {
          return "Great. Based on what you’ve shared, we’d guide you toward a therapist who has experience with similar concerns and preferences.";
        } else if (state.nextStep.includes("therapy is like")) {
          return "Totally fair. Many people want to understand what to expect before starting. We’d walk you through what sessions typically look like and how to find a good fit.";
        } else {
          return "That makes sense. Sometimes starting with small, concrete coping strategies can make the idea of therapy feel more approachable later.";
        }
      },
    },
    {
      type: "bot",
      text: "This is just a short demo, but this kind of flow can be extended into a full intake or guidance experience.",
    },
  ];

  // --- Build stepId -> index map for branching ---
  const stepIndexById = {};
  conversationScript.forEach((step, index) => {
    if (step.stepId) {
      stepIndexById[step.stepId] = index;
    }
  });

  function getNextIndex(currentIndex, step, options = {}) {
    const { choiceValue } = options;

    // 1. If this is a choice with branches and we have a match, follow that
    if (step.branches && choiceValue && step.branches[choiceValue]) {
      const target = step.branches[choiceValue];
      if (typeof target === "number") return target;
      if (typeof target === "string" && stepIndexById[target] != null) {
        return stepIndexById[target];
      }
    }

    // 2. Otherwise, if step has a 'next', follow it
    if (step.next != null) {
      if (typeof step.next === "number") {
        return step.next;
      }
      if (typeof step.next === "string" && stepIndexById[step.next] != null) {
        return stepIndexById[step.next];
      }
    }

    // 3. Fallback: go to the next step in sequence
    return currentIndex + 1;
  }

  // --- DOM wiring ---

  const chatLogEl = document.getElementById("chat-log");
  const chatInputAreaEl = document.getElementById("chat-input-area");

  let currentStepIndex = 0;
  const state = {};

  function addBubble(text, role) {
    const bubble = document.createElement("div");
    bubble.className = `chat-bubble ${role}`;
    bubble.textContent = text;
    chatLogEl.appendChild(bubble);
    chatLogEl.scrollTop = chatLogEl.scrollHeight;
  }

  async function callLLM(userText, endpointOverride) {
    const url = endpointOverride || API_URL;

    const response = await fetch(url, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ message: userText }),
    });

    if (!response.ok) {
      console.error("LLM error:", await response.text());
      return "Sorry, I’m having trouble responding right now.";
    }

    const data = await response.json();
    return data.reply || data.summary || JSON.stringify(data);
  }

  // Typing indicator

  let typingEl = null;

  function showTypingIndicator(text = "Thinking…") {
    if (typingEl) return; // avoid duplicates

    typingEl = document.createElement("div");
    typingEl.className = "chat-bubble bot";
    typingEl.innerHTML = `
      <div class="typing-indicator">
        <span>${text}</span>
        <div class="typing-dots">
          <span></span><span></span><span></span>
        </div>
      </div>
    `;
    chatLogEl.appendChild(typingEl);
    chatLogEl.scrollTop = chatLogEl.scrollHeight;
  }

  function hideTypingIndicator() {
    if (typingEl && typingEl.parentNode) {
      typingEl.parentNode.removeChild(typingEl);
    }
    typingEl = null;
  }

  // --- Main step renderer with branching ---

  function renderStep() {
    chatInputAreaEl.innerHTML = ""; // clear input area

    if (currentStepIndex >= conversationScript.length) {
      return;
    }

    const step = conversationScript[currentStepIndex];

    // BOT
    if (step.type === "bot") {
      const raw =
        typeof step.text === "function" ? step.text(state) : step.text;

      showTypingIndicator();
      chatInputAreaEl.innerHTML = "";

      setTimeout(() => {
        hideTypingIndicator();
        addBubble(raw, "bot");
        const nextIndex = getNextIndex(currentStepIndex, step);
        currentStepIndex = nextIndex;
        setTimeout(renderStep, 500);
      }, 500);
    }

    // USER INPUT
    else if (step.type === "userInput") {
      addBubble(step.prompt, "bot");

      const wrapper = document.createElement("div");
      const textarea = document.createElement("textarea");
      textarea.rows = 3;
      textarea.placeholder = "Type your response here...";

      const submitBtn = document.createElement("button");
      submitBtn.textContent = "Submit";
      submitBtn.className = "primary";

      submitBtn.addEventListener("click", () => {
        const value = textarea.value.trim();
        if (!value) return;

        addBubble(value, "user");
        state[step.id] = value;

        chatInputAreaEl.innerHTML = "";
        const nextIndex = getNextIndex(currentStepIndex, step);
        currentStepIndex = nextIndex;
        renderStep();
      });

      wrapper.appendChild(textarea);
      wrapper.appendChild(submitBtn);
      chatInputAreaEl.appendChild(wrapper);
    }

    // CHOICE
    else if (step.type === "choice") {
      addBubble(step.prompt, "bot");

      const wrapper = document.createElement("div");
      wrapper.className = "choice-buttons";

      step.choices.forEach((choiceText) => {
        const btn = document.createElement("button");
        btn.type = "button";
        btn.textContent = choiceText;

        btn.addEventListener("click", () => {
          addBubble(choiceText, "user");
          state[step.id] = choiceText;

          chatInputAreaEl.innerHTML = "";
          const nextIndex = getNextIndex(currentStepIndex, step, {
            choiceValue: choiceText,
          });
          currentStepIndex = nextIndex;
          renderStep();
        });

        wrapper.appendChild(btn);
      });

      chatInputAreaEl.appendChild(wrapper);
    }

    // LLM INPUT (free-text step that calls LLM immediately)
    else if (step.type === "llmInput") {
      addBubble(step.prompt, "bot");

      const wrapper = document.createElement("div");
      const textarea = document.createElement("textarea");
      textarea.rows = 3;
      textarea.placeholder = "Type your response here...";

      const submitBtn = document.createElement("button");
      submitBtn.textContent = "Submit";
      submitBtn.className = "primary";

      submitBtn.addEventListener("click", async () => {
        const value = textarea.value.trim();
        if (!value) return;

        addBubble(value, "user");
        state[step.id] = value;
        chatInputAreaEl.innerHTML = "";

        showTypingIndicator("Thinking about your response…");
        const llmReply = await callLLM(value, step.endpoint);
        hideTypingIndicator();

        addBubble(llmReply, "bot");

        const nextIndex = getNextIndex(currentStepIndex, step);
        currentStepIndex = nextIndex;
        renderStep();
      });

      wrapper.appendChild(textarea);
      wrapper.appendChild(submitBtn);
      chatInputAreaEl.appendChild(wrapper);
    }

    // LLM BOT (auto-call LLM using previous state[source])
    else if (step.type === "llmBot") {
      const sourceId = step.source;
      const inputText = state[sourceId];

      if (!inputText) {
        addBubble(
          "I don’t have enough information yet to respond.",
          "bot"
        );
        const nextIndex = getNextIndex(currentStepIndex, step);
        currentStepIndex = nextIndex;
        setTimeout(renderStep, 500);
        return;
      }

      chatInputAreaEl.innerHTML = "";
      showTypingIndicator();

      (async () => {
        const llmReply = await callLLM(inputText, step.endpoint);
        hideTypingIndicator();

        addBubble(llmReply, "bot");

        if (step.id) {
          state[step.id] = llmReply;
        }

        const nextIndex = getNextIndex(currentStepIndex, step);
        currentStepIndex = nextIndex;
        renderStep();
      })();
    }
  }

  // Kick off the scripted conversation
  renderStep();
</script>



</html>
